---
title: "solution_script"
author: "Charles"
date: "19 8 2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

## **Description**

The task consists of finding groups or clusters within a dataset consisting of 49 patients (observations) who provided various responses about 12 factors (variables) that motivate them. Each value is basically the mean value of about 7 questions people answered in the particular category/variable. 

This is basically an unsupervised clustering problem. Clustering is a form of exploratory data analysis (EDA) whereby observations are grouped into meaningful groups, based on features they share.

I will use various approaches to identify and confirm the optimal number of groups of patients within the dataset. These approaches will fall under the following milestones:

1. Data pre-processing
2. Select similarity metric
3. Clustering
4. Analyses

## **Setup**

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = TRUE)
```

## **Load libraries**

```{r libraries}
library(openxlsx)
library(ggplot2)
library(purrr)
library(dplyr)
library(tidyr)
```

## **Load in the dataset**

```{r data_set}
list.files("raw_data")

# read in the data
raw_data <- read.xlsx("raw_data/Vinyu_Motivation_Challenge_Test.xlsx", 
                      rowNames = TRUE)
```

## **Step 1: Data pre-processing.**

This is to explore for missing values and to make sure the data are on the same scale. This is because based on my presumption, these values were very unlikely to be on the same scale.

### ***i. Check for missing values.**

```{r check_NA}
anyNA(raw_data) # check for NAs

# inspect
View(raw_data) 
dim(raw_data)
```

Result shows the absence of missing values in the dataset.

### **ii. Standardise the the features.**

I will perform standardisation. This will help make the data comparable, since it is unlikely that they were measured on the same scale. Without standardisation, distances between samples may become exagerated and unmeaningful. I will make use of base R's $scale()$ function. Each feature column will be normalised to a mean of 0 and a variance of 1.

```{r scaling}
# scale the data
scaled_data <- scale(raw_data)
```

## **Step 2: The similarity metric.**

The similarity metric I will use is the distance. So I will compute the distance between each samples, using base R's $dist()$ function which calculates the Euclidean distance by default.

```{r dist}
# calculate the distance
dist_scaled_data <- dist(scaled_data)
```

## **Step 3: Clustering.**

### **i. Hierarchical clustering.**

We can perform hierarchical clustering based on the distances defined above using the $hclust()$ function. This function returns an `hclust` object that describes the groupings that were created using the algorithm described above. The `plot` method represents these relationships with a tree or dendrogram: 


```{r Hclust}
library(rafalib) # to optimise graphical parameters.
mypar()
hc <- hclust(dist_scaled_data)
hc
plot(hc, cex = 0.5, asp = 1)
```

The hierarchical clustering is consistent with the existence to two main clusters. So I define two clusters, and I cut the tree at height value 9 group all samples that are within that distance into groups below. To visualize this, I will draw a horizontal line at the height I wish to cut and this defines that line. I start with 9.

```{r clust_assignment}
myplclust(hc,cex = 0.5)
abline(h = 9)

# cut tree
hclusters <- cutree(hc, h = 9)
print(hclusters)
```

Results show which cluster each patient belongs to.

### **ii. K-Means clustering.**

We can also cluster with the `kmeans` function to perform k-means clustering. I will estimate the otimal number of Ks using two appraoches: 

#### Leveraging the total within-cluster sum of squares

I will use $map_dbl()$ from the $purrr$ library to run k-means using values of k ranging from 1 to 10 and extract the total within-cluster sum of squares.

```{r within_cluster}
```


```{r Kmeans}
We can also cluster with the `kmeans` function to perform k-means clustering. As an example, let's run k-means on the samples in the space of the first two genes:
```

